{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pickle\n",
    "from time import time\n",
    "import warnings\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer, LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from scipy.stats import expon, randint\n",
    "\n",
    "np.random.seed(17)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cordectomy 59\n",
    "# Dysodie 56\n",
    "# Dysphonia 101\n",
    "# Hyperfunctional_dysphonia 211\n",
    "# Hypofunctional_dysphonia 16\n",
    "# Hypotonic_dysphonia 5\n",
    "# Laryngitis 140\n",
    "# Polyp 45\n",
    "# Reinke_edema 68\n",
    "# Spasmodic_dysphonia 64\n",
    "# VC_carcinoma 22\n",
    "# VFP 211\n",
    "# Healthy sample size: 634\n",
    "# Choose Dysphonia, Hyperfunctional_dysphonia, Laryngitis, VFP\n",
    "\n",
    "# pathology_names = ['Cordectomy', 'Dysodie', 'Dysphonia', 'Hyperfunctional_dysphonia',\n",
    "#                    'Hypofunctional_dysphonia', 'Hypotonic_dysphonia', 'Laryngitis', 'Polyp', 'Reinke_edema',\n",
    "#                    'Spasmodic_dysphonia', 'VC_carcinoma', 'VFP']\n",
    "\n",
    "pathology_names = ['Dysphonia', 'Hyperfunctional_dysphonia', 'Laryngitis', 'VFP']\n",
    "audio_contents = ['i', 'a', 'u', 'phrase']\n",
    "pitchs = ['h', 'l', 'n', 'lhl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use classic machine learning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class run_multiple_classifiers():\n",
    "    def __init__(self, features, labels):\n",
    "        self.X = features\n",
    "        self.le = LabelEncoder()\n",
    "        self.y = self.le.fit_transform(labels)\n",
    "        self.best_results = {}\n",
    "        self.classifiers = []\n",
    "        self.best_estimator = None\n",
    "        self.time_cost = 0.0\n",
    "        \n",
    "    def _svm(self):\n",
    "        params_dist = {'classifier__gamma': expon(scale=0.1),\n",
    "                       'classifier__C': expon(scale=10)}\n",
    "        model = SVC()\n",
    "        name = 'SVM'\n",
    "        self.classifiers.append((params_dist, model, name))\n",
    "    \n",
    "    def _rf(self):\n",
    "        params_dist = {'classifier__max_features': randint(1,5),\n",
    "                       'classifier__max_depth': [3, None],\n",
    "                       'classifier__min_samples_split': randint(2, 11),\n",
    "                       'classifier__min_samples_leaf': randint(1, 11),\n",
    "                       'classifier__bootstrap': [True, False]}\n",
    "        model = RandomForestClassifier()\n",
    "        name = 'RandomForest'\n",
    "        self.classifiers.append((params_dist, model, name))\n",
    "        \n",
    "    def _logisticReg(self):\n",
    "        params_dist = {'classifier__C': expon(scale=1)}\n",
    "        model = LogisticRegression()\n",
    "        name = 'LogisticRegression'\n",
    "        self.classifiers.append((params_dist, model, name))\n",
    "        \n",
    "    def _gaussianMix(self):\n",
    "        params_dist = {'classifier__n_components': randint(1,10),\n",
    "                      'classifier__weight_concentration_prior': expon(0.1),\n",
    "                      'classifier__covariance_type' : ['full', 'tied', 'diag', 'spherical']}\n",
    "        model = BayesianGaussianMixture()\n",
    "        name = 'BayesianGaussianMixture'\n",
    "        self.classifiers.append((params_dist, model, name))\n",
    "        \n",
    "    def _kNN(self):\n",
    "        params_dist = {'classifier__n_neighbors': randint(2,15),\n",
    "                      'classifier__weights': ['uniform', 'distance']}\n",
    "        model = KNeighborsClassifier()\n",
    "        name = 'kNN'\n",
    "        self.classifiers.append((params_dist, model, name))\n",
    "        \n",
    "    def _MLP(self):\n",
    "        params_dist = {'classifier__hidden_layer_sizes': [(5,5), (5,5,3), (4,4,4)],\n",
    "                      'classifier__alpha': expon(0.0001)}\n",
    "        model = MLPClassifier()\n",
    "        name = 'MLP'\n",
    "        self.classifiers.append((params_dist, model, name))\n",
    "        \n",
    "    def _DT(self):\n",
    "        params_dist = {'classifier__criterion':['gini', 'entropy'],\n",
    "                     'classifier__min_samples_split':randint(2,10)}\n",
    "        model = DecisionTreeClassifier()\n",
    "        name = 'DecisionTree'\n",
    "        self.classifiers.append((params_dist, model, name))\n",
    "    \n",
    "    def run_classifier(self):\n",
    "        start = time()\n",
    "        self._svm()\n",
    "        self._rf()\n",
    "        self._logisticReg()\n",
    "        self._gaussianMix()\n",
    "        self._kNN()\n",
    "#         self._MLP()\n",
    "        self._DT()\n",
    "        clfs = self.classifiers.copy()\n",
    "        best_of_all = 0.0\n",
    "        for pd, model, name in clfs:\n",
    "            fs_pd = {'featureSelection__k': randint(self.X.shape[1]//10, self.X.shape[1]//2)}\n",
    "            pipe = Pipeline([('scaler',StandardScaler()),('featureSelection',SelectKBest()),('classifier',model)])\n",
    "            params_dist = {**fs_pd, **pd}\n",
    "            grid = RandomizedSearchCV(pipe, param_distributions=params_dist, n_iter=20, cv=5, n_jobs=-1, random_state=17, scoring='accuracy')\n",
    "            grid.fit(self.X, self.y)\n",
    "            self.best_results[name] = float('{0:.3f}'.format(grid.best_score_))\n",
    "            if grid.best_score_>best_of_all:\n",
    "                best_of_all = grid.best_score_\n",
    "                self.best_estimator = grid.best_estimator_\n",
    "        for pd, model, name in self.classifiers:\n",
    "            pipe = Pipeline([('scaler',StandardScaler()),('featureSelection',PCA(n_components='mle', svd_solver='full')),('classifier',model)])\n",
    "            grid = RandomizedSearchCV(pipe, param_distributions=pd, n_iter=20, cv=5, n_jobs=-1, random_state=17, scoring='accuracy')\n",
    "            grid.fit(self.X, self.y)\n",
    "            if grid.best_score_>self.best_results[name]:\n",
    "                self.best_results[name] = float('{0:.3f}'.format(grid.best_score_))\n",
    "                if grid.best_score_>best_of_all:\n",
    "                    best_of_all = grid.best_score_\n",
    "                    self.best_estimator = grid.best_estimator_\n",
    "        self.time_cost = time()-start\n",
    "            \n",
    "    def display_results(self):\n",
    "        print(self.best_results)\n",
    "        print('Time cost is: {0:.2f}s'.format(self.time_cost))\n",
    "        \n",
    "    def save_best_model(self, name):\n",
    "        joblib.dump(self.best_estimator, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class audio_data:\n",
    "    def __init__(self, name=''):\n",
    "        self.name = name\n",
    "        self.i = {}\n",
    "        self.a = {}\n",
    "        self.u = {}\n",
    "        self.phrase = []\n",
    "\n",
    "class AudioFeature:\n",
    "    def __init__(self, audio_files, n_mfcc=20):\n",
    "        self.name = audio_files.name\n",
    "        self.phrase = audio_files.phrase\n",
    "        self.sample_size = len(audio_files.phrase)\n",
    "        self.i = audio_files.i\n",
    "        self.a = audio_files.a\n",
    "        self.u = audio_files.u\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.p_mfcc = []\n",
    "        self.iau_mfcc = []\n",
    "        self.labels = []\n",
    "        self.extract_mfcc_features(self.n_mfcc)\n",
    "        self.create_labels()\n",
    "        \n",
    "    def extract_mfcc_features(self, n_mfcc):\n",
    "        for p_file in self.phrase:\n",
    "            mfccs = self.extract_mfcc(p_file, n_mfcc)\n",
    "            self.p_mfcc.append(mfccs)\n",
    "        for i in range(self.sample_size):\n",
    "            mfcc_vector = np.array([])\n",
    "            for content in (self.i, self.a, self.u):\n",
    "                for pitch in pitchs:\n",
    "                    mfccs = self.extract_mfcc(content[pitch][i], n_mfcc)\n",
    "                    mfcc_vector = np.hstack((mfcc_vector,mfccs))\n",
    "            self.iau_mfcc.append(mfcc_vector)\n",
    "        self.p_mfcc = np.array(self.p_mfcc)\n",
    "        self.iau_mfcc = np.array(self.iau_mfcc)\n",
    "        \n",
    "    def create_labels(self):\n",
    "        self.labels = np.array([self.name]*self.sample_size)\n",
    "            \n",
    "    def extract_mfcc(self, file, n_mfcc):\n",
    "        data, sr = librosa.load(file)\n",
    "        mfccs = librosa.feature.mfcc(data, sr, n_mfcc=n_mfcc)\n",
    "        return np.mean(mfccs.T, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use mfcc features: n_mfcc=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mfcc_{n_mfcc}/{name}_mfcc_{n_mfcc}.pkl'.format(name='healthy',n_mfcc=4),'rb') as f:\n",
    "    h_mfcc4 = pickle.load(f)\n",
    "\n",
    "h_iau_mfcc4 = h_mfcc4.iau_mfcc\n",
    "h_label = h_mfcc4.labels\n",
    "\n",
    "h_iau_mfcc4.shape, h_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mfcc = 4\n",
    "mfccs = []\n",
    "for p_name in pathology_names:\n",
    "    with open('mfcc_{n_mfcc}/{name}_mfcc_{n_mfcc}.pkl'.format(name=p_name,n_mfcc=n_mfcc),'rb') as f:\n",
    "        p_mfcc = pickle.load(f)\n",
    "    p_iau_mfcc = p_mfcc.iau_mfcc\n",
    "    mfccs.append(p_iau_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((663, 48), (663,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_iau_mfcc4 = np.concatenate(mfccs)\n",
    "p_label = np.array(['pathology']*p_iau_mfcc4.shape[0])\n",
    "p_iau_mfcc4.shape, p_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1297, 48), (1297,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc4_all = np.concatenate((h_iau_mfcc4, p_iau_mfcc4))\n",
    "label_all = np.concatenate((h_label, p_label))\n",
    "mfcc4_all.shape, label_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "run1_mfcc4 = run_multiple_classifiers(mfcc4_all, label_all)\n",
    "\n",
    "run1_mfcc4.run_classifier()\n",
    "run1_mfcc4.display_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('featureSelection', PCA(copy=True, iterated_power='auto', n_components='mle', random_state=None,\n",
       "  svd_solver='full', tol=0.0, whiten=False)), ('classifier', BayesianGaussianMixture(covariance_prior=None, covariance_type='...ration_prior=0.27311456500103126,\n",
       "            weight_concentration_prior_type='dirichlet_process'))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run1_mfcc4.best_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use mfcc features: n_mfcc=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((634, 144), (634,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_mfcc=12\n",
    "with open('mfcc_{n_mfcc}/{name}_mfcc_{n_mfcc}.pkl'.format(name='healthy',n_mfcc=n_mfcc),'rb') as f:\n",
    "    h_mfcc12 = pickle.load(f)\n",
    "\n",
    "h_iau_mfcc12 = h_mfcc12.iau_mfcc\n",
    "h_label = h_mfcc12.labels\n",
    "\n",
    "h_iau_mfcc12.shape, h_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((663, 144), (663,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_mfcc = 12\n",
    "mfccs = []\n",
    "for p_name in pathology_names:\n",
    "    with open('mfcc_{n_mfcc}/{name}_mfcc_{n_mfcc}.pkl'.format(name=p_name,n_mfcc=n_mfcc),'rb') as f:\n",
    "        p_mfcc = pickle.load(f)\n",
    "    p_iau_mfcc = p_mfcc.iau_mfcc\n",
    "    mfccs.append(p_iau_mfcc)\n",
    "p_iau_mfcc12 = np.concatenate(mfccs)\n",
    "p_label = np.array(['pathology']*p_iau_mfcc12.shape[0])\n",
    "p_iau_mfcc12.shape, p_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1297, 144), (1297,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc12_all = np.concatenate((h_iau_mfcc12, p_iau_mfcc12))\n",
    "label_all = np.concatenate((h_label, p_label))\n",
    "mfcc12_all.shape, label_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run1_mfcc12 = run_multiple_classifiers(mfcc12_all, label_all)\n",
    "\n",
    "run1_mfcc12.run_classifier()\n",
    "run1_mfcc12.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use deep learning approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.1, input_shape=(48,)))\n",
    "# model.add(Dense(30, activation='relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_1 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                980       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,201\n",
      "Trainable params: 1,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "mfcc4_all_scaled = scaler.fit_transform(mfcc4_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(label_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(mfcc4_all_scaled, labels, test_size=0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1037 samples, validate on 260 samples\n",
      "Epoch 1/50\n",
      "1037/1037 [==============================] - 0s 34us/step - loss: 0.3939 - acc: 0.8274 - val_loss: 0.5544 - val_acc: 0.7308\n",
      "Epoch 2/50\n",
      "1037/1037 [==============================] - 0s 36us/step - loss: 0.3881 - acc: 0.8168 - val_loss: 0.5598 - val_acc: 0.7231\n",
      "Epoch 3/50\n",
      "1037/1037 [==============================] - 0s 34us/step - loss: 0.3885 - acc: 0.8197 - val_loss: 0.5583 - val_acc: 0.7154\n",
      "Epoch 4/50\n",
      "1037/1037 [==============================] - 0s 35us/step - loss: 0.3729 - acc: 0.8361 - val_loss: 0.5634 - val_acc: 0.7231\n",
      "Epoch 5/50\n",
      "1037/1037 [==============================] - 0s 34us/step - loss: 0.3888 - acc: 0.8216 - val_loss: 0.5639 - val_acc: 0.7192\n",
      "Epoch 6/50\n",
      "1037/1037 [==============================] - 0s 37us/step - loss: 0.4062 - acc: 0.8091 - val_loss: 0.5680 - val_acc: 0.7192\n",
      "Epoch 7/50\n",
      "1037/1037 [==============================] - 0s 36us/step - loss: 0.3913 - acc: 0.8303 - val_loss: 0.5639 - val_acc: 0.7231\n",
      "Epoch 8/50\n",
      "1037/1037 [==============================] - 0s 36us/step - loss: 0.3795 - acc: 0.8264 - val_loss: 0.5687 - val_acc: 0.7231\n",
      "Epoch 9/50\n",
      "1037/1037 [==============================] - 0s 35us/step - loss: 0.3785 - acc: 0.8341 - val_loss: 0.5661 - val_acc: 0.7231\n",
      "Epoch 10/50\n",
      "1037/1037 [==============================] - 0s 36us/step - loss: 0.3772 - acc: 0.8351 - val_loss: 0.5642 - val_acc: 0.7308\n",
      "Epoch 11/50\n",
      "1037/1037 [==============================] - 0s 36us/step - loss: 0.3952 - acc: 0.8284 - val_loss: 0.5622 - val_acc: 0.7269\n",
      "Epoch 12/50\n",
      "1037/1037 [==============================] - 0s 35us/step - loss: 0.3865 - acc: 0.8255 - val_loss: 0.5657 - val_acc: 0.7308\n",
      "Epoch 13/50\n",
      "1037/1037 [==============================] - 0s 36us/step - loss: 0.3794 - acc: 0.8322 - val_loss: 0.5673 - val_acc: 0.7308\n",
      "Epoch 14/50\n",
      "1037/1037 [==============================] - 0s 36us/step - loss: 0.3701 - acc: 0.8341 - val_loss: 0.5587 - val_acc: 0.7192\n",
      "Epoch 15/50\n",
      "1037/1037 [==============================] - 0s 36us/step - loss: 0.3847 - acc: 0.8284 - val_loss: 0.5718 - val_acc: 0.7154\n",
      "Epoch 16/50\n",
      "1037/1037 [==============================] - 0s 35us/step - loss: 0.3895 - acc: 0.8235 - val_loss: 0.5785 - val_acc: 0.7269\n",
      "Epoch 17/50\n",
      "1037/1037 [==============================] - 0s 38us/step - loss: 0.4026 - acc: 0.8023 - val_loss: 0.5662 - val_acc: 0.7308\n",
      "Epoch 18/50\n",
      "1037/1037 [==============================] - 0s 36us/step - loss: 0.3719 - acc: 0.8438 - val_loss: 0.5722 - val_acc: 0.7115\n",
      "Epoch 19/50\n",
      "1037/1037 [==============================] - 0s 36us/step - loss: 0.3828 - acc: 0.8197 - val_loss: 0.5834 - val_acc: 0.7231\n",
      "Epoch 20/50\n",
      "1037/1037 [==============================] - 0s 37us/step - loss: 0.3796 - acc: 0.8293 - val_loss: 0.5875 - val_acc: 0.7154\n",
      "Epoch 21/50\n",
      "1037/1037 [==============================] - 0s 38us/step - loss: 0.3793 - acc: 0.8264 - val_loss: 0.5863 - val_acc: 0.7269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f5f39b0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=50, callbacks=[EarlyStopping(patience=20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
